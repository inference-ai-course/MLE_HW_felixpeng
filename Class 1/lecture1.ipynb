{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36e8482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.97.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openai\n",
    "!{sys.executable} -m pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860c6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d65a7",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16261f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801243c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd62e2",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. It has applications in various fields, including healthcare, finance, and transportation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacaf35",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21090582",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Extract the age and location from the same text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b407b2",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27717cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96271ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a5914",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88533315",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec224a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd94d7",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598b87d1",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de00ab",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbac816",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f715782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d462bf",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72165962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c7ece",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e353f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fd137",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ddfb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
